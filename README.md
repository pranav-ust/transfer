# Sandwiching Transferred Models of Sparse Vectors in Deep Learning

The task assigned was to predict the trading action that the user is likely to read according to app contents about users by using transfer learning. While implementing deep learning architectures, we observed the non-convergence of common loss functions. Hence we proposed masked loss function which could mask the sparsity information in the loss function. Further, we proposed an autoen- coder based model by sandwiching two distinctly trained networks together. We then introduced a novel architecture, bi-directional autoencoders which produces two outputs for a single input vectors. The backward pass of the network based on the alternating gradient optimization methods. Finally, through our experiments, bi-directional autoencoders outperforms the rest of the given models.

![Poster](https://github.com/pranav-ust/transfer/poster.png)

View the detailed report [here](https://github.com/pranav-ust/transfer/sandwiching-transferred-models.pdf)
